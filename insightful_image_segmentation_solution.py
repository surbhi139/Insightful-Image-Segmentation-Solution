# -*- coding: utf-8 -*-
"""Insightful Image Segmentation Solution.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1f-obPjvUQfuwMSAM6jQaJWBPUpb1PhhN
"""

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
sns.set(style='whitegrid')

#from wordcloud import WordCloud
import tensorflow as tf
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA, TruncatedSVD
from sklearn.metrics import classification_report,confusion_matrix
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Embedding, LSTM,Dense, SpatialDropout1D, Dropout
from keras.initializers import Constant

# Reset individual options to default
pd.reset_option('display.max_columns')
pd.reset_option('display.max_rows')
pd.reset_option('display.max_colwidth')

# Set desired options
pd.set_option('display.max_columns', 100)
pd.set_option('display.max_rows', 900)
pd.set_option('display.max_colwidth', 200)

import warnings
warnings.filterwarnings("ignore")

train = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/training.csv',header=None)
validation = pd.read_csv('/kaggle/input/sentiment-analysis-dataset/validation.csv',header=None)

train.columns=['Tweet ID','Entity','Sentiment','Tweet Content']
validation.columns=['Tweet ID','Entity','Sentiment','Tweet Content']

print("Training DataSet: \n")
train = train.sample(5000)
display(train.head())

print("Validation DataSet: \n")
display(validation.head())

train = train.dropna(subset=['Tweet Content'])

display(train.isnull().sum())
print("*****"* 5)
display(validation.isnull().sum())

duplicates = train[train.duplicated(subset=['Entity', 'Sentiment', 'Tweet Content'], keep=False)]
train = train.drop_duplicates(subset=['Entity', 'Sentiment', 'Tweet Content'], keep='first')

duplicates = validation[validation.duplicated(subset=['Entity', 'Sentiment', 'Tweet Content'], keep=False)]
validation = validation.drop_duplicates(subset=['Entity', 'Sentiment', 'Tweet Content'], keep='first')

import pandas as pd

# Assuming 'train' and 'validation' are your DataFrames

# Calculate sentiment counts for train and validation data
sentiment_counts_train = train['Sentiment'].value_counts()
sentiment_counts_validation = validation['Sentiment'].value_counts()

# Combine counts into a single DataFrame
combined_counts = pd.concat([sentiment_counts_train, sentiment_counts_validation], axis=1)

# Fill missing values (if any) with 0
combined_counts.fillna(0, inplace=True)

# Rename columns
combined_counts.columns = ['Test Data', 'Validation Data']  # Set desired column names

combined_counts

import pandas as pd
import matplotlib.pyplot as plt

# Assuming 'train' and 'validation' are your DataFrames

# Calculate sentiment counts
sentiment_counts_train = train['Sentiment'].value_counts()
sentiment_counts_validation = validation['Sentiment'].value_counts()

# Create subplots for side-by-side comparison
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))  # Adjust figsize for better view

# Create pie chart for training data
ax1.pie(sentiment_counts_train, labels=sentiment_counts_train.index, autopct='%1.1f%%', colors=['gold', 'lightcoral', 'lightskyblue','#99FF99'])
ax1.set_title('Sentiment Distribution (Training Data)', fontsize=20)

# Create pie chart for validation data
ax2.pie(sentiment_counts_validation, labels=sentiment_counts_validation.index, autopct='%1.1f%%', colors=['gold', 'lightcoral', 'lightskyblue','#99FF99'])
ax2.set_title('Sentiment Distribution (Validation Data)', fontsize=20)

# Adjust layout for better visualization
plt.tight_layout()
plt.show()

# Calculate the value counts of 'Entity'
entity_counts = train['Entity'].value_counts()

# Get the top 9 names
top_names = entity_counts.head(19)

# Aggregate the tenth name as 'Other'
other_count = entity_counts[19:].sum()
top_names['Other'] = other_count

# Display the top 19 names and 'Other'
top_names.to_frame()

import plotly.express as px
import plotly.graph_objects as go
import plotly.io as pio

# Calculate the percentages
percentages = (top_names / top_names.sum()) * 100

# Create the pie chart
fig = go.Figure(data=[go.Pie(
    labels=percentages.index,
    values=percentages,
    textinfo='label+percent',
    insidetextorientation='radial'
)])

# Update layout
fig.update_layout(
    title_text='Top Names with Percentages',
    showlegend=False
)

# Show the plot
fig.show()

from tensorflow.keras.layers import Input, Dropout, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.initializers import TruncatedNormal
from tensorflow.keras.losses import CategoricalCrossentropy
from tensorflow.keras.metrics import CategoricalAccuracy
from tensorflow.keras.utils import to_categorical

import pandas as pd
from sklearn.model_selection import train_test_split

import pandas as pd
import plotly.graph_objects as go

# Assuming you've already run the data preprocessing steps
data = train[['Tweet Content', 'Sentiment']]

# Set your model output as categorical and save in new label col
data['Sentiment_label'] = pd.Categorical(data['Sentiment'])

# Transform your output to numeric
data['Sentiment'] = data['Sentiment_label'].cat.codes

# Use the entire training data as data_train
data_train = data

# Use validation data as data_test
data_test = validation[['Tweet Content', 'Sentiment']]
data_test['Sentiment_label'] = pd.Categorical(data_test['Sentiment'])
data_test['Sentiment'] = data_test['Sentiment_label'].cat.codes

# Create a colorful table using Plotly
fig = go.Figure(data=[go.Table(
    header=dict(
        values=list(data_train.columns),
        fill_color='paleturquoise',
        align='left',
        font=dict(color='black', size=12)
    ),
    cells=dict(
        values=[data_train[k].tolist()[:10] for k in data_train.columns],
        fill_color=[
            'lightcyan',  # Tweet Content
            ['lightgreen' if s == 'Positive' else 'lightpink' if s == 'Negative'
              else 'lightyellow' if s == 'Neutral' else 'lightgray' for s in data_train['Sentiment_label'][:10]],  # Sentiment
            ['lightgreen' if s == 'Positive' else 'lightpink' if s == 'Negative'
              else 'lightyellow' if s == 'Neutral' else 'lightgray' for s in data_train['Sentiment_label'][:10]],  # Sentiment_label
            'lavender'  # Sentiment (numeric)
        ],
        align='left',
        font=dict(color='black', size=11)
    ))
])

# Update the layout
fig.update_layout(
    title='First 10 Rows of Training Data',
    width=1000,
    height=500,
)

fig.show()

import plotly.graph_objects as go

# Create a colorful table using Plotly for the test data
fig = go.Figure(data=[go.Table(
    header=dict(
        values=list(data_test.columns),
        fill_color='paleturquoise',
        align='left',
        font=dict(color='black', size=12)
    ),
    cells=dict(
        values=[data_test[k].tolist()[:5] for k in data_test.columns],  # Show first 5 rows
        fill_color=[
            'lightcyan',  # Tweet Content
            ['lightgreen' if s == 'Positive' else 'lightpink' if s == 'Negative'
             else 'lightyellow' if s == 'Neutral' else 'lightgray' for s in data_test['Sentiment_label'][:5]],  # Sentiment
            ['lightgreen' if s == 'Positive' else 'lightpink' if s == 'Negative'
             else 'lightyellow' if s == 'Neutral' else 'lightgray' for s in data_test['Sentiment_label'][:5]],  # Sentiment_label
            'lavender'  # Sentiment (numeric)
        ],
        align='left',
        font=dict(color='black', size=11)
    ))
])

# Update the layout
fig.update_layout(
    title='First 5 Rows of Test Data',
    width=1000,
    height=500,
)

# Show the figure
fig.show()

# If you want to save the figure as an HTML file, uncomment the following line:
# fig.write_html("test_data_sample.html")

"""# BERT (Bidirectional Encoder Representations from Transformers)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import BertTokenizer, BertForSequenceClassification, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the dataF
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 2, 'Negative': 0, 'Neutral': 1, 'Irrelevant': 3})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         encoding = self.tokenizer.encode_plus(
#             text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             return_token_type_ids=False,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': encoding['input_ids'].flatten(),
#             'attention_mask': encoding['attention_mask'].flatten(),
#             'labels': torch.tensor(label, dtype=torch.long)
#         }
# 
# # Initialize tokenizer and create datasets
# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model_BERT
# model_BERT = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_BERT.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_BERT.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_BERT.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_BERT(input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_BERT.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels']
#             outputs = model_BERT(input_ids, attention_mask=attention_mask)
#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()
#             test_preds.extend(preds)
#             test_true.extend(labels.numpy())
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# 
# # Save the model_BERT
# torch.save(model_BERT.state_dict(), 'sentiment_model_BERT.pth')

# Final evaluation
print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))

# Assuming test_true and test_preds are defined
from sklearn.metrics import confusion_matrix

# Check if test_true labels need conversion (optional)
if not isinstance(test_true[0], str):  # If labels are not strings
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    test_true_encoded = encoder.fit_transform(test_true)  # Encode labels
    labels = [0, 1, 2, 3]  # Numerical labels
else:
    test_true_encoded = test_true
    labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels

# Calculate confusion matrix with consistent labels
confusion_matrix_BERT = confusion_matrix(test_true_encoded, test_preds, labels=labels)

print("Confusion matrix BERT \n")
confusion_matrix_BERT

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels
test_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_BERT, display_labels=labels)
test_display.plot(cmap='Blues')
plt.title("Test Set - Confusion Matrix")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# RoBERTa (Robustly Optimized BERT Pretraining Approach)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import BertTokenizer, BertForSequenceClassification, AdamW
# from transformers import RobertaTokenizer, RobertaForSequenceClassification, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the data
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 2, 'Negative': 0, 'Neutral': 1, 'Irrelevant': 3})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         encoding = self.tokenizer.encode_plus(
#             text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             return_token_type_ids=False,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': encoding['input_ids'].flatten(),
#             'attention_mask': encoding['attention_mask'].flatten(),
#             'labels': torch.tensor(label, dtype=torch.long)
#         }
# 
# # Initialize tokenizer and create datasets
# #tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model
# #model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=4)
# model_RoBERTa = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=4)
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_RoBERTa.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_RoBERTa.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_RoBERTa.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_RoBERTa(input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_RoBERTa.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels']
#             outputs = model_RoBERTa(input_ids, attention_mask=attention_mask)
#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()
#             test_preds.extend(preds)
#             test_true.extend(labels.numpy())
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# 
# # Save the model
# torch.save(model_RoBERTa.state_dict(), 'sentiment_RoBERTa_model.pth')

# Final evaluation
print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))

# Assuming test_true and test_preds are defined
from sklearn.metrics import confusion_matrix

# Check if test_true labels need conversion (optional)
if not isinstance(test_true[0], str):  # If labels are not strings
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    test_true_encoded = encoder.fit_transform(test_true)  # Encode labels
    labels = [0, 1, 2, 3]  # Numerical labels
else:
    test_true_encoded = test_true
    labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels

# Calculate confusion matrix with consistent labels
confusion_matrix_RoBERTa = confusion_matrix(test_true_encoded, test_preds, labels=labels)

print("Confusion matrix RoBERTa \n")
confusion_matrix_RoBERTa

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels
test_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_RoBERTa, display_labels=labels)
test_display.plot(cmap='Blues')
plt.title("Test Set - Confusion Matrix")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# DistilBERT (Distilled version of BERT)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the data
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 2, 'Negative': 0, 'Neutral': 1, 'Irrelevant': 3})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         encoding = self.tokenizer.encode_plus(
#             text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             return_token_type_ids=False,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': encoding['input_ids'].flatten(),
#             'attention_mask': encoding['attention_mask'].flatten(),
#             'labels': torch.tensor(label, dtype=torch.long)
#         }
# 
# # Initialize tokenizer and create datasets
# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model DistilBERT
# model_DistilBERT = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=4)
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_DistilBERT.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_DistilBERT.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_DistilBERT.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_DistilBERT(input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_DistilBERT.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels']
#             outputs = model_DistilBERT(input_ids, attention_mask=attention_mask)
#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()
#             test_preds.extend(preds)
#             test_true.extend(labels.numpy())
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# 
# # Save the model_DistilBERT
# torch.save(model_DistilBERT.state_dict(), 'sentiment_model_distilbert.pth')

# Final evaluation
print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))

# Assuming test_true and test_preds are defined
from sklearn.metrics import confusion_matrix

# Check if test_true labels need conversion (optional)
if not isinstance(test_true[0], str):  # If labels are not strings
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    test_true_encoded = encoder.fit_transform(test_true)  # Encode labels
    labels = [0, 1, 2, 3]  # Numerical labels
else:
    test_true_encoded = test_true
    labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels

# Calculate confusion matrix with consistent labels
confusion_matrix_DistilBERT = confusion_matrix(test_true_encoded, test_preds, labels=labels)

print("Confusion matrix DistilBERT \n")
confusion_matrix_DistilBERT

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels
test_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_DistilBERT, display_labels=labels)
test_display.plot(cmap='Blues')
plt.title("Test Set - Confusion Matrix")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# ALBERT (A Lite BERT)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# 
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import AlbertTokenizer, AlbertForSequenceClassification, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the data
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 2, 'Negative': 0, 'Neutral': 1, 'Irrelevant': 3})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         encoding = self.tokenizer.encode_plus(
#             text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': encoding['input_ids'].flatten(),
#             'attention_mask': encoding['attention_mask'].flatten(),
#             'labels': torch.tensor(label, dtype=torch.long)
#         }
# 
# # Initialize tokenizer and create datasets
# tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model
# model_ALBERT = AlbertForSequenceClassification.from_pretrained('albert-base-v2', num_labels=4)
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_ALBERT.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_ALBERT.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_ALBERT.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_ALBERT(input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_ALBERT.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels']
#             outputs = model_ALBERT(input_ids, attention_mask=attention_mask)
#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()
#             test_preds.extend(preds)
#             test_true.extend(labels.numpy())
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# # Final evaluation
# print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))
# 
# # Save the model
# torch.save(model_ALBERT.state_dict(), 'sentiment_model_albert.pth')

# Final evaluation
print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))

# Assuming test_true and test_preds are defined
from sklearn.metrics import confusion_matrix

# Check if test_true labels need conversion (optional)
if not isinstance(test_true[0], str):  # If labels are not strings
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    test_true_encoded = encoder.fit_transform(test_true)  # Encode labels
    labels = [0, 1, 2, 3]  # Numerical labels
else:
    test_true_encoded = test_true
    labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels

# Calculate confusion matrix with consistent labels
confusion_matrix_ALBERT = confusion_matrix(test_true_encoded, test_preds, labels=labels)

print("Confusion matrix ALBERT \n")
confusion_matrix_ALBERT

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels
test_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_ALBERT, display_labels=labels)
test_display.plot(cmap='Blues')
plt.title("Test Set - Confusion Matrix")
plt.grid(False)
plt.tight_layout()
plt.show()

"""# XLNet"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import XLNetTokenizer, XLNetForSequenceClassification, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the data
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 2, 'Negative': 0, 'Neutral': 1, 'Irrelevant': 3})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         encoding = self.tokenizer.encode_plus(
#             text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_token_type_ids=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': encoding['input_ids'].flatten(),
#             'attention_mask': encoding['attention_mask'].flatten(),
#             'token_type_ids': encoding['token_type_ids'].flatten(),
#             'labels': torch.tensor(label, dtype=torch.long)
#         }
# 
# # Initialize tokenizer and create datasets
# tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model XLNet
# model_XLNet = XLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=4)
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_XLNet.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_XLNet.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_XLNet.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         token_type_ids = batch['token_type_ids'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_XLNet(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_XLNet.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             token_type_ids = batch['token_type_ids'].to(device)
#             labels = batch['labels']
#             outputs = model_XLNet(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)
#             preds = torch.argmax(outputs.logits, dim=1).cpu().numpy()
#             test_preds.extend(preds)
#             test_true.extend(labels.numpy())
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# # Save the model_XLNet
# torch.save(model_XLNet.state_dict(), 'sentiment_model_xlnet.pth')

# Final evaluation
print(classification_report(test_true, test_preds, target_names=['Negative', 'Neutral', 'Positive', 'Irrelevant']))

# Assuming test_true and test_preds are defined
from sklearn.metrics import confusion_matrix

# Check if test_true labels need conversion (optional)
if not isinstance(test_true[0], str):  # If labels are not strings
    from sklearn.preprocessing import LabelEncoder
    encoder = LabelEncoder()
    test_true_encoded = encoder.fit_transform(test_true)  # Encode labels
    labels = [0, 1, 2, 3]  # Numerical labels
else:
    test_true_encoded = test_true
    labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels

# Calculate confusion matrix with consistent labels
confusion_matrix_XLNet = confusion_matrix(test_true_encoded, test_preds, labels=labels)

print("Confusion matrix XLNet \n")
confusion_matrix_XLNet

from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay
labels = ['Negative', 'Neutral', 'Positive', 'Irrelevant']  # String labels
test_display = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_XLNet, display_labels=labels)
test_display.plot(cmap='Blues')
plt.title("Test Set - Confusion Matrix")
plt.grid(False)
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Data for the bar graph (only Trial 1)
models = ["BERT", "RoBERTa", "DistilBERT", "ALBERT", "XLNet"]

accuracy_trial_1 = [67.3, 67.50, 69.60, 61.3, 63.1]

# Set up the plot
fig, ax = plt.subplots(figsize=(10, 8))

# Set the width of each bar and the positions of the bars
width = 0.7

# Create bars with different colors
colors = ['blue', 'green', 'orange', 'purple', 'red', 'magenta']
ax.bar(models, accuracy_trial_1, width, color=colors)

# Customize the plot
ax.set_ylabel('Accuracy (%)', fontsize=12)  # Increase font size for y-axis label
ax.set_xlabel('Machine Learning Model', fontsize=18)  # Increase font size for x-axis label
ax.set_title('Accuracy of Machine Learning Models (Trial 1)', fontsize=14)  # Increase font size for title

# Setxticks and rotate x-axis labels for better readability
ax.set_xticks(models)
ax.set_xticklabels(models, rotation=45, ha='right', fontsize=11)  # Increase font size for x-axis tick labels

# Add value labels on top of each bar with increased font size
for i, v in enumerate(accuracy_trial_1):
    ax.text(i, v + 0.2, f'{v:.1f}', ha='center', va='bottom', fontsize=16)  # Adjust vertical offset and format to one decimal place

# Set y-axis to start at 0
ax.set_ylim(0, 100)

# Add gridlines
ax.grid(axis='y', linestyle='--', alpha=0.9)

plt.tight_layout()
plt.show()

"""# T5 (Text-to-Text Transfer Transformer)"""

# Commented out IPython magic to ensure Python compatibility.
# %%time
# import pandas as pd
# import torch
# from torch.utils.data import Dataset, DataLoader
# from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW
# from sklearn.metrics import accuracy_score, classification_report
# 
# # Preprocess the data
# def preprocess_data(df):
#     df['label'] = df['Sentiment_label'].map({'Positive': 'positive', 'Negative': 'negative', 'Neutral': 'neutral', 'Irrelevant': 'irrelevant'})
#     return df['Tweet Content'].tolist(), df['label'].tolist()
# 
# train_texts, train_labels = preprocess_data(data_train)
# test_texts, test_labels = preprocess_data(data_test)
# 
# # Create a custom dataset
# class SentimentDataset(Dataset):
#     def __init__(self, texts, labels, tokenizer, max_len=128):
#         self.texts = texts
#         self.labels = labels
#         self.tokenizer = tokenizer
#         self.max_len = max_len
# 
#     def __len__(self):
#         return len(self.texts)
# 
#     def __getitem__(self, idx):
#         text = str(self.texts[idx])
#         label = self.labels[idx]
# 
#         # Prepare input
#         input_text = f"sentiment classification: {text}"
#         input_encoding = self.tokenizer.encode_plus(
#             input_text,
#             add_special_tokens=True,
#             max_length=self.max_len,
#             padding='max_length',
#             truncation=True,
#             return_attention_mask=True,
#             return_tensors='pt',
#         )
# 
#         # Prepare target
#         target_encoding = self.tokenizer.encode_plus(
#             label,
#             add_special_tokens=True,
#             max_length=10,  # Assuming labels are short
#             padding='max_length',
#             truncation=True,
#             return_tensors='pt',
#         )
# 
#         return {
#             'input_ids': input_encoding['input_ids'].flatten(),
#             'attention_mask': input_encoding['attention_mask'].flatten(),
#             'labels': target_encoding['input_ids'].flatten()
#         }
# 
# # Initialize tokenizer and create datasets
# tokenizer = T5Tokenizer.from_pretrained('t5-small')
# train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)
# test_dataset = SentimentDataset(test_texts, test_labels, tokenizer)
# 
# # Create data loaders
# train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
# test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)
# 
# # Initialize the model T5
# model_T5 = T5ForConditionalGeneration.from_pretrained('t5-small')
# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
# model_T5.to(device)
# 
# # Set up optimizer
# optimizer = AdamW(model_T5.parameters(), lr=2e-5)
# 
# # Training loop
# num_epochs = 3
# 
# for epoch in range(num_epochs):
#     model_T5.train()
#     for batch in train_loader:
#         optimizer.zero_grad()
#         input_ids = batch['input_ids'].to(device)
#         attention_mask = batch['attention_mask'].to(device)
#         labels = batch['labels'].to(device)
#         outputs = model_T5(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
#         loss = outputs.loss
#         loss.backward()
#         optimizer.step()
# 
#     # Evaluation on test set
#     model_T5.eval()
#     test_preds = []
#     test_true = []
#     with torch.no_grad():
#         for batch in test_loader:
#             input_ids = batch['input_ids'].to(device)
#             attention_mask = batch['attention_mask'].to(device)
#             labels = batch['labels']
#             outputs = model_T5.generate(input_ids=input_ids, attention_mask=attention_mask, max_length=10)
#             preds = [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]
#             test_preds.extend(preds)
#             test_true.extend([tokenizer.decode(label, skip_special_tokens=True) for label in labels])
# 
#     accuracy = accuracy_score(test_true, test_preds)
#     print(f'Epoch {epoch + 1}/{num_epochs}, Test Accuracy: {accuracy:.4f}')
# 
# 
# # Save the model_T5
# torch.save(model_T5.state_dict(), 'sentiment_model_t5.pth')